<!DOCTYPE html>
<html>
    <head>
        <title>Risks</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="icon" href="./Resources/Images/favicon.png">
        <link rel="stylesheet" href="./Resources/CSS/main.css">
    </head>
    <body>
        <div class="grid-container">
            <!--Navigation bar-->
            <nav>
                <a href="./index.html">Topic</a>
                <a href="./opportunities.html">Opportunities</a>
                <a href="./risks.html">Risks</a>
                <a href="./choices.html">Choices</a>
                <a href="./references.html">References</a>
            </nav>

            <!--body-->
            <main>
                <h1>Social Media Algorithm Risks</h1>

                <section>
                    <h2>The Mental Health Impact of Social Media</h2>
                    <p>Prolonged exposure to social media platforms has been increasingly linked to a decline in mental health, particularly among teenagers and young adults. Numerous studies have established a strong correlation between high levels of screen time and the prevalence of anxiety, depression, and low self-esteem. Young users are especially vulnerable as they often compare themselves to the curated, idealised personas presented by peers and influencers online. This relentless self-comparison can lead to feelings of inadequacy and emotional distress. Research published by SAGE Journals underscores the psychological toll of constantly engaging with idealised content, concluding that such exposure contributes significantly to mental health challenges (Khan et al., 2014).</p>
                    <p>Adding weight to this concern, the former U.S. Surgeon General has proposed that social media platforms carry warning labels, similar to those on tobacco products, due to their detrimental effects on young people's mental well-being (Khan et al., 2014). This move reflects a growing awareness among public health officials about the widespread consequences of digital media on psychological development. As evidence mounts, the need for regulatory and educational responses becomes more pressing to safeguard vulnerable populations.</p>
                </section>
                <img src="./Resources/Images/socialmediaoverwhelming.jpg" alt="Social media overwhelming person">
                <section>
                    <h2>The Viral Nature of Misinformation</h2>
                    <p>Social media platforms are inherently designed to prioritise engagement, often at the cost of accuracy. Algorithms that reward clicks, shares, and emotional responses inadvertently amplify misinformation, allowing false or misleading content to spread more rapidly than verified information. This has serious implications for public trust, especially during critical periods like elections or global health crises. Studies in ScienceDirect have shown that these algorithmic models disproportionately reward sensational or emotionally charged content, undermining informed discourse (Everett, 2010).</p>
                    <p>The COVID-19 pandemic serves as a striking example of this dynamic. Misinformation regarding vaccines, treatments, and virus origins often gained more traction than accurate, scientifically backed information. This distortion not only hampered public health efforts but also eroded trust in institutions and experts. Addressing the misinformation epidemic requires both technological and policy-driven interventions to recalibrate how truth and engagement are balanced online.</p>
                </section>
                <section>
                    <h2>Political Polarisation and Echo Chambers</h2>
                    <p>One of the most concerning consequences of algorithmically curated content is its role in deepening political polarisation. Social media users are frequently exposed only to viewpoints that align with their existing beliefs, creating ideological echo chambers. This filtering effect limits users' exposure to diverse perspectives, reinforcing biases and facilitating radicalisation. Research from Emerald Insight highlights how these digital bubbles intensify societal divides and contribute to an “us vs them” mentality (Baird & Parasnis, 2011).</p>
                    <p>The real-world implications of this polarisation are profound. Events such as the January 6th U.S. Capitol riots underscore how online radicalisation can translate into violent action. When platforms prioritise engagement over balanced representation of ideas, they risk becoming catalysts for social unrest. Recognising and mitigating this risk is essential to preserving democratic discussions and civil discourse.</p>
                </section>
                <section>
                    <h2>Cyberbullying and Online Harassment</h2>
                    <p>The anonymity and reach of social media creates fertile ground for cyberbullying and online harassment. These toxic behaviours can have devastating psychological effects, particularly on younger users. Victims of cyberbullying often experience heightened levels of anxiety, depression, and even suicidal ideation. According to SpringerLink, adolescents subjected to online abuse are more likely to disengage academically and suffer from long-term emotional distress (Naslund et al., 2020).</p>
                    <p>One notable case involves Australian radio host Kymba Cahill, who publicly quit social media after being relentlessly targeted by online trolls (Kirk, 2025). Her experience highlights how widespread and damaging digital harassment can be, affecting both public figures and ordinary users alike. Tackling this issue demands stronger moderation practices, better reporting mechanisms, and education on digital empathy and responsibility.</p>
                </section>
                <img src="./Resources/Images/cyberbullying.jpg" alt="Person being cyberbullied">
                <section>
                    <h2>Invasion of Data Privacy</h2>
                    <p>Another pressing issue surrounding social media use is the widespread collection and exploitation of user data. Platforms harvest vast amounts of personal information - often with limited user awareness - to fuel targeted advertising and behavioural profiling. Studies from Emerald reveal that most users unknowingly consent to opaque terms of service that grant companies sweeping access to their digital footprints (Baird & Parasnis, 2011).</p>
                    <p>The Cambridge Analytica scandal brought this issue into sharp relief, exposing how personal data was weaponised to influence political behaviour and public opinion. Such breaches of trust highlight the urgent need for stronger privacy protections and greater transparency in how user data is collected, stored, and used. Without reform, the ethical implications of mass data exploitation will continue to grow.</p>
                </section>
                <section>
                    <h2>Algorithmic Manipulation and Autonomy Loss</h2>
                    <p>Closely related to privacy concerns is the issue of algorithmic manipulation. Social media algorithms do more than just filter content - they shape users' perceptions, beliefs, and behaviours by nudging them toward specific types of information. Many users remain unaware of how profoundly these systems influence their digital experiences. Research from ScienceDirect confirms that this covert curation undermines user autonomy and the capacity to make truly informed decisions (Everett, 2010).</p>
                    <p>The danger lies in the illusion of choice. Users may believe they are navigating platforms freely, while in reality, their exposure is heavily mediated by opaque and profit-driven algorithms. This subtle manipulation has profound implications for civic engagement, consumer behaviour, and personal identity formation. As awareness grows, so too does the call for algorithmic transparency and user control.</p>
                </section>
                <section>
                    <h2>The Allure (and Danger) of Viral Challenges</h2>
                    <p>The quest for online recognition has led to the rise of viral challenges, many of which encourage risky and harmful behaviour. Driven by a desire for likes, shares, and peer validation, young people may engage in stunts that result in serious injury or even death. While academic literature on this topic is still developing, observations suggest that algorithmic virality plays a central role in spreading these dangerous trends.</p>
                    <p>A tragic case from New Zealand involved a 12-year-old boy who died while attempting the "Run It Straight" challenge - a social media trend that dared users to run head-first into objects or people (Corlett, 2025). This incident is a sobering reminder of how online platforms can influence behaviour with real-world consequences. Preventive education and stricter content moderation are crucial to curbing such outcomes.</p>
                </section>
                <img src="./Resources/Images/ostracised.jpg" alt="Person ostracised by peers">
                <section>
                    <h2>Decline of In-Person Social Skills</h2>
                    <p>Excessive reliance on digital communication is also contributing to the erosion of real-life social skills. Young people, in particular, are increasingly choosing texting or direct messaging over in-person interaction. According to SpringerLink, this shift can hinder emotional development, reduce empathy, and impair the ability to resolve conflicts effectively (Naslund et al., 2020).</p>
                    <p>The long-term consequences of this trend may include increased loneliness, social anxiety, and a diminished capacity for meaningful interpersonal relationships. As digital communication becomes the norm, it is essential to encourage balanced usage that includes real-world socialisation and emotional learning.</p>
                </section>
                <section>
                    <h2>The Attention Economy and Ethical Trade-Offs</h2>
                    <p>At the heart of many of these issues lies the business model of social media itself. Platforms are designed to capture and retain user attention, often by amplifying polarising or emotionally charged content. This “attention economy,” as critiqued by Emerald, prioritises corporate profit over user well-being or societal stability (Baird & Parasnis, 2011).</p>
                    <p>By monetising outrage and sensationalism, social media companies contribute to a cycle of engagement that is detrimental to mental health and social cohesion. Ethical concerns arise regarding how these platforms are structured and what responsibilities they hold toward their users. Addressing these concerns requires both industry self-regulation and external oversight.</p>
                </section>
                <section>
                    <h2>Manipulation of Public Discourse</h2>
                    <p>Lastly, social media platforms have become arenas for the manipulation of public discourse through bots, paid influencers, and coordinated misinformation campaigns. Research from SAGE documents how such interference (often state-sponsored) undermines democratic processes and erodes the quality of public dialogue (Khan et al., 2014).</p>
                    <p>From the U.S. elections and Brexit to the global response to COVID-19, disinformation campaigns have been used to sway opinion and disrupt governance. This manipulation threatens the integrity of public institutions and the very foundation of informed citizenship. As digital platforms become more central to everyday life, defending them against such abuses is necessary.</p>
                </section>
            </main>

            <!--footer-->
            <footer>
                <span>This website is for COMP501 Group 96 Semester 1 2025</span>
            </footer>

        </div>
    </body>
</html>